# Fake News Detection using Word Embeddings

This project demonstrates how to build a fake news detection model using word embeddings generated by `gensim`'s Word2Vec model trained on Google News and text preprocessing with `spaCy`.

## Project Goal

The goal of this project is to classify news articles as either "Fake" or "Real" using machine learning techniques applied to word embeddings.

## Technologies Used

*   **Python:** The primary programming language used for the project.
*   **Google Colab:** The environment where the code was developed and executed.
*   **`gensim`:** Used for loading the pre-trained Word2Vec model (`word2vec-google-news-300`) and generating word embeddings.
*   **`spaCy`:** Used for efficient text preprocessing, including tokenization and lemmatization, to prepare the text data for vectorization.
*   **`pandas`:** Used for data loading, manipulation, and analysis.
*   **`numpy`:** Used for numerical operations, particularly for handling the word embedding vectors.
*   **`scikit-learn`:** Used for splitting the data into training and testing sets, training a Gradient Boosting Classifier model, and evaluating its performance using a classification report and confusion matrix.
*   **`matplotlib` and `seaborn`:** Used for visualizing the confusion matrix.

## Project Steps

1.  **Install Libraries:** Installed necessary libraries including `gensim`, `numpy`, and `scipy`.
2.  **Download Word2Vec Model:** Downloaded the pre-trained `word2vec-google-news-300` model using `gensim.downloader`.
3.  **Load Data:** Loaded the fake and real news dataset from a CSV file into a pandas DataFrame.
4.  **Data Preparation:**
    *   Mapped the "Fake" and "Real" labels to numerical values (0 and 1).
    *   Downloaded the `en_core_web_lg` spaCy model for text processing.
    *   Defined a function to preprocess text (tokenization, removing stop words and punctuation, lemmatization) and generate a mean vector embedding for each news article using the Word2Vec model.
    *   Applied the preprocessing and vectorization function to the 'Text' column of the DataFrame to create a new 'vector' column containing the word embeddings.
5.  **Split Data:** Split the dataset into training and testing sets using `train_test_split`.
6.  **Train Model:** Trained a `GradientBoostingClassifier` model on the training data.
7.  **Evaluate Model:** Evaluated the model's performance using a classification report and confusion matrix.
8.  **Make Predictions:** Used the trained model to make predictions on new, unseen news articles.

## How to Run the Project

1.  Clone the repository to your local machine.
2.  Open the Jupyter Notebook or Colab notebook file.
3.  Ensure you have the required libraries installed (you can use the provided `!pip install` commands in the notebook).
4.  Run the notebook cells sequentially.

## Dataset

The dataset used in this project is `fake_and_real_news.csv`. It contains news articles labeled as either "Fake" or "Real".

## Results

The Gradient Boosting Classifier achieved an accuracy of 98% on the test set, with high precision, recall, and f1-scores for both classes, as shown in the classification report and confusion matrix.

## Confusion Matrix

The confusion matrix visualizes the performance of the classification model.
